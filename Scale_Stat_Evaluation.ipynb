{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Scale_Stat_Evaluation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNcl8fp2Yo89CYI/SuuObSY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/frapasti/Embedded-Person-detection/blob/main/Scale_Stat_Evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Scale statistics evaluation\n",
        "This notebook aims to evaluate the performances of some off the shelf person detectors with metrics such as precision, recall, miss rate and f1 score over different input scales.\n",
        "\n",
        "First of all, install the needed libraries"
      ],
      "metadata": {
        "id": "sE6gNFwDXgjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fiftyone --no-binary fiftyone,voxel51-eta\n",
        "import fiftyone as fo\n",
        "import fiftyone.zoo as foz\n",
        "import numpy as np\n",
        "from numpy import expand_dims\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from matplotlib import pyplot\n",
        "from matplotlib.patches import Rectangle\n",
        "import json\n",
        "import cv2\n",
        "import imutils\n",
        "from google.colab.patches import cv2_imshow\n",
        "from keras.preprocessing.image import load_img\n",
        "import fiftyone.zoo as foz\n",
        "from fiftyone import ViewField as F\n",
        "import os\n",
        "\n",
        "def listdir_fullpath(d):\n",
        "    return [os.path.join(d, f) for f in os.listdir(d)]"
      ],
      "metadata": {
        "id": "R1WbsfosYZwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATASET DOWNLOAD\n",
        "In order to evaluate over different scales the input images must start from the same size.\n",
        "The chosen size is 640x480.\n",
        "The dataset is downloaded with the fiftyone tool for coco-2017"
      ],
      "metadata": {
        "id": "ji-mtSy9X__v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#DATASET containing persons\n",
        "dataset = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split=\"validation\",\n",
        "    label_types=[\"detections\"],\n",
        "    classes=[\"person\"],\n",
        "    only_matching = True,\n",
        "    max_samples=1000,\n",
        ")"
      ],
      "metadata": {
        "id": "omtbyj3faTDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c363f3e-dadb-4cbf-8f90-f31ede67495a"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'validation' to '/root/fiftyone/coco-2017/validation' if necessary\n",
            "Downloading annotations to '/root/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n",
            " 100% |██████|    1.9Gb/1.9Gb [2.8s elapsed, 0s remaining, 695.0Mb/s]       \n",
            "Extracting annotations to '/root/fiftyone/coco-2017/raw/instances_val2017.json'\n",
            "Downloading 1000 images\n",
            " 100% |████████████████| 1000/1000 [1.5m elapsed, 0s remaining, 11.5 images/s]      \n",
            "Writing annotations for 1000 downloaded samples to '/root/fiftyone/coco-2017/validation/labels.json'\n",
            "Dataset info written to '/root/fiftyone/coco-2017/info.json'\n",
            "Loading 'coco-2017' split 'validation'\n",
            " 100% |███████████████| 1000/1000 [5.0s elapsed, 0s remaining, 206.4 samples/s]      \n",
            "Dataset 'coco-2017-validation-1000' created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('/root/fiftyone/coco-2017/validation/labels.json')\n",
        "data = json.load(f)\n",
        "annotations = data['annotations']\n",
        "every_path = []\n",
        "cols = 10\n",
        "rows = 1000\n",
        "bbox_size = 4\n",
        "counters = [0] * rows\n",
        "bboxes = [[] for i in range(rows)] \n",
        "items = 0\n",
        "# Creation of the list of paths of images in the dataset and bboxes\n",
        "# This elements are extracted from the json file downloaded from coco with the dataset\n",
        "for entry in data['annotations']:\n",
        "    class_id = entry['category_id']\n",
        "    if (class_id == 1):\n",
        "        img_id = entry['image_id']\n",
        "        path = float(img_id)/pow(10,11)\n",
        "        dec_path = format(path, '.11f')\n",
        "        final_path = ''\n",
        "        final_path = '/root/fiftyone/coco-2017/validation/data/'+ dec_path.replace('.', '') + '.jpg'\n",
        "        if(every_path.count(final_path) == 0):\n",
        "          every_path.append(final_path)\n",
        "          bboxes[items].append(entry['bbox'])\n",
        "          items = items + 1\n",
        "        else:\n",
        "          index = every_path.index(final_path)\n",
        "          if(counters[index] + 1 < 10):\n",
        "            bboxes[index].append(entry['bbox'])\n",
        "            counters[index] = counters[index] + 1\n",
        "\n",
        "# Matain only images of size 640x480\n",
        "f_every_path = []\n",
        "f_bboxes = []\n",
        "for i in range(0, len(every_path)):\n",
        "  original_img = load_img(every_path[i])\n",
        "  width, height = original_img.size\n",
        "  if(width == 640 and height == 480):\n",
        "    f_every_path.append(every_path[i])\n",
        "    f_bboxes.append(bboxes[i])\n",
        "\n",
        "assert(len(bboxes)==len(every_path))"
      ],
      "metadata": {
        "id": "9TA_AVg2aLzL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DATASET of non persons\n",
        "dataset1 = foz.load_zoo_dataset(\n",
        "    \"coco-2017\",\n",
        "    split=\"train\",\n",
        "    label_types=[\"detections\"],\n",
        "    only_matching = True,\n",
        "    max_samples=500,\n",
        ")\n",
        "\n",
        "class_name = \"Person\"\n",
        "\n",
        "# Find samples that have a \"Person\"\n",
        "pos_view = dataset1.filter_labels(\"ground_truth\", F(\"label\")==class_name)\n",
        "\n",
        "# Find all samples without a positively labeled \"Person\"\n",
        "neg_view = dataset1.exclude(pos_view)\n",
        "\n",
        "# Tag any samples that have a person in the App with \"remove\"\n",
        "session = fo.launch_app(view=neg_view)"
      ],
      "metadata": {
        "id": "cXJNaPvYNqsQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d21ebf-eb1c-41a6-9315-470ebd8aa18a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading split 'train' to '/root/fiftyone/coco-2017/train' if necessary\n",
            "Found annotations at '/root/fiftyone/coco-2017/raw/instances_train2017.json'\n",
            "Downloading 500 images\n",
            "  16% |██/---------------|  80/500 [6.8s elapsed, 35.6s remaining, 11.7 images/s]    "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find and remove all tagged samples from the DatasetView\n",
        "neg_view = neg_view.match_tags(\"remove\", bool=False)\n",
        "\n",
        "neg_view.export(\n",
        "    export_dir=\"/content/nonPerson1\",\n",
        "    dataset_type=fo.types.COCODetectionDataset,\n",
        ")\n",
        "\n",
        "# Mantain only images of size 640x480\n",
        "non_persons = listdir_fullpath(\"/content/nonPerson1/data\")\n",
        "for i in range(0, len(non_persons)):\n",
        "  original_img = load_img(non_persons[i])\n",
        "  width, height = original_img.size\n",
        "  if(width == 640 and height == 480):\n",
        "    f_every_path.append(non_persons[i])\n",
        "    f_bboxes.append([])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O2cc9SBWcvTr",
        "outputId": "ef18df6e-3f74-4216-fb94-d3b6caf36bda"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 100% |█████████████████| 461/461 [1.8s elapsed, 0s remaining, 263.4 samples/s]         \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(f_every_path))\n",
        "print(len(f_bboxes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88ZByaf_WIOS",
        "outputId": "833e8d5d-3987-407e-9be1-8a8c64b600c3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "224\n",
            "224\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "vIGGFtA9W2Wa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}